# LLM Configuration for Article Generation

# LLM Provider Settings
llm:
  # Provider type: "openai", "ollama", "custom"
  provider: "custom"

  # Writer Model Configuration
  writer:
    model: "doubao-seed-1-6-flash-250828"
    api_base: "https://ark.cn-beijing.volces.com/api/v3"
    api_key: "a8509ac0-ea82-4d50-b284-8f826988677d"
    temperature: 0.7
    max_tokens: 8000
    timeout: 180

  # Retry Configuration
  retry:
    max_retries: 3
    retry_delay: 2

# Example configurations for different providers:
#
# For OpenAI:
#   provider: "openai"
#   writer:
#     model: "gpt-4o"
#     api_key: "${OPENAI_API_KEY}"
#
# For Ollama (local):
#   provider: "ollama"
#   writer:
#     model: "qwen2.5:14b"
#     api_base: "http://localhost:11434/v1"
#     api_key: "ollama"
